# -*- coding: utf-8 -*-
"""betty.james (25 Mar 2025, 14:56:44)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/embedded/projects/data-science-911/locations/us-central1/repositories/f70a534f-3338-4e9e-abff-a4b8da804715

**CAT BOOST**
"""

!pip install google-cloud-storage

import pandas as pd

df = pd.read_csv('gs://betty_101/processed_space_objects_data.csv')

# Take 10% random sample (adjust frac as needed)
test_sample = df.sample(frac=0.1, random_state=42)

print(f"Created sample with {len(test_sample)} records")
print(test_sample.head())

test_sample.to_csv('voting_clf_test_sample.csv', index=False)

test_sample = pd.read_csv('voting_clf_test_sample.csv')

sample_df = pd.read_csv('/content/voting_clf_test_sample.csv')

sample_df.shape

sample_df.info()

# Columns to drop
columns_to_drop = [
    'MESSAGE TIME (UTC)',
    'EPOCH TIME (UTC)',
    'SATELLITE NUMBER',
    'MESSAGE_HOUR',
    'MESSAGE_DAYOFWEEK',
    'EPOCH_HOUR',
    'EPOCH_DAYOFWEEK'
]

zero_value_cols = sample_df.columns[sample_df.isnull().all()].tolist()  # Automatically finds empty columns
columns_to_drop += zero_value_cols

sample_df_clean = sample_df.drop(columns=columns_to_drop)

print(f"Original shape: {sample_df.shape}")
print(f"New shape: {sample_df_clean.shape}")
print("\nRemaining columns:")
print(sample_df_clean.columns.tolist())

categorical_cols = [
    'GEOPOTENTIAL', 'DRAG', 'SOLAR RAD PRESS',
    'SOLID EARTH TIDES', 'IN-TRACK THRUST',

    'INTEGRATOR MODE', 'PARTIALS', 'STEP MODE',
    'FIXED STEP', 'STEP SIZE SELECTION', 'ERROR CONTROL'
]

numerical_cols = [col for col in sample_df_clean.columns
                 if col not in categorical_cols + ['OBJECT_TYPE']]

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(
    sample_df_clean.drop('OBJECT_TYPE', axis=1),
    sample_df_clean['OBJECT_TYPE'],
    test_size=0.2,
    stratify=sample_df_clean['OBJECT_TYPE'],
    random_state=42
)

for col in categorical_cols:
    X_train[col] = X_train[col].astype('category')
    X_test[col] = X_test[col].astype('category')

scaler = StandardScaler()
X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])
X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])

from catboost import Pool, CatBoostClassifier

cat_features = [X_train.columns.get_loc(col) for col in categorical_cols]

train_pool = Pool(
    X_train, y_train,
    cat_features=cat_features,
    feature_names=list(X_train.columns)
)

test_pool = Pool(
    X_test, y_test,
    cat_features=cat_features,
    feature_names=list(X_test.columns)
)

from sklearn.metrics import classification_report

model = CatBoostClassifier(
    iterations=500,
    learning_rate=0.05,
    depth=6,
    loss_function='MultiClass',
    eval_metric='Accuracy',
    random_seed=42,
    verbose=100
)

model.fit(train_pool, eval_set=test_pool)

y_pred = model.predict(test_pool)
print(classification_report(y_test, y_pred))

feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': model.get_feature_importance()
}).sort_values('importance', ascending=False)

print("\nTop Space Object Features:")
print(feature_importance.head(10))

import joblib

joblib.dump({
    'model': model,
    'scaler': scaler,
    'categorical_cols': categorical_cols,
    'numerical_cols': numerical_cols,
    'feature_names': list(X_train.columns)
}, 'space_object_catboost.pkl')

print("Model saved as space_object_catboost.pkl")

