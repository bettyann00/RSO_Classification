# -*- coding: utf-8 -*-
"""betty.james (9 Apr 2025, 16:55:09)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/embedded/projects/data-science-911/locations/us-central1/repositories/98845a3c-dca1-49a3-8a01-a8ebff096837
"""

!pip install catboost
!pip install lightgbm

# === 1. IMPORT LIBRARIES ===
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, accuracy_score, fbeta_score
import matplotlib.pyplot as plt
import joblib
import pickle
from datetime import datetime

# === 2. LOAD DATA ===
df = pd.read_csv("gs://betty_101/processed_space_objects_data.csv")

# === 3. DROP UNUSED COLUMNS ===
columns_to_drop = [
    'MESSAGE TIME (UTC)', 'EPOCH TIME (UTC)', 'OBJECT_TYPE', 'SATELLITE NUMBER'
]
categorical_columns = [
    'GEOPOTENTIAL', 'DRAG', 'SOLAR RAD PRESS', 'SOLID EARTH TIDES', 'IN-TRACK THRUST'
]
label_column = 'OBJECT_TYPE'

# === 4. BALANCE DATA BY SATELLITE NUMBER ===
sample_per_sat = 100  # Reduced sample size
balanced_df = (
    df.groupby('SATELLITE NUMBER')
      .apply(lambda x: x.sample(n=min(len(x), sample_per_sat), random_state=42))
      .reset_index(drop=True)
)

# === 5. SEPARATE LABEL ===
labels = balanced_df[label_column]
X = balanced_df.drop(columns=columns_to_drop)

# === 6. ENCODE CATEGORICAL FEATURES ===
le_dict = {}
for col in categorical_columns:
    le = LabelEncoder()
    X[col] = le.fit_transform(X[col].astype(str))
    le_dict[col] = le

# === 7. ENCODE LABEL ===
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(labels)

# === 8. SCALE FEATURES ===
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# === 9. SPLIT DATA ===
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# === 10. HANDLE CLASS IMBALANCE ===
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train),
    y=y_train
)
class_weights_dict = {i: w for i, w in enumerate(class_weights)}

# === 11. EVALUATION FUNCTION WITH F2 SCORE ===
def evaluate_model(name, model, X, y_true):
    y_pred = model.predict(X)
    print(f"\n{name} Classification Report")
    print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))
    print("Accuracy:", accuracy_score(y_true, y_pred))

    # Calculate F2 score (beta=2 gives more weight to recall)
    f2 = fbeta_score(y_true, y_pred, average='weighted', beta=2)
    print("F2 Score (weighted):", f2)

    return f2

# === 12. FIRST STAGE: RANDOM FOREST FEATURE SELECTION ===
print("\n=== PHASE 1: RANDOM FOREST FEATURE SELECTION ===")
rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
rf.fit(X_train, y_train)

# Initialize F2 scores dictionary
f2_scores = {'RandomForest': evaluate_model("RandomForest", rf, X_test, y_test)}

# === 13. FEATURE IMPORTANCE ===
feature_importances = rf.feature_importances_
features = X.columns
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})
importance_df = importance_df.sort_values('Importance', ascending=False)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'])
plt.title('Random Forest Feature Importance')
plt.xlabel('Importance Score')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.savefig('feature_importance.png')
plt.show()

# Select top features (adjust threshold as needed)
top_features = importance_df[importance_df['Importance'] > 0.01]['Feature'].tolist()
print(f"\nSelected {len(top_features)} top features:", top_features)

# Get indices of top features
top_feature_indices = [list(X.columns).index(f) for f in top_features]
X_train_top = X_train[:, top_feature_indices]
X_test_top = X_test[:, top_feature_indices]

# === 14. VOTING CLASSIFIER ===

!pip install --upgrade scikit-learn xgboost catboost lightgbm

from sklearn.ensemble import VotingClassifier
from sklearn.base import clone

models = {
    'xgb': clone(XGBClassifier(
        objective='multi:softprob',
        num_class=num_classes,
        use_label_encoder=False,
        eval_metric='mlogloss',
        random_state=42
    )),
    'cat': clone(CatBoostClassifier(
        loss_function='MultiClass',
        class_weights=class_weights.tolist(),
        random_state=42,
        verbose=0,
        allow_writing_files=False  # Prevents CatBoost from writing files
    )),
    'lgb': clone(LGBMClassifier(
        class_weight='balanced',
        random_state=42
    ))
}

# Train individual models first
f2_scores = {}
for name, model in models.items():
    print(f"\nTraining {name}...")
    model.fit(X_train_top, y_train)
    f2_scores[name] = evaluate_model(name, model, X_test_top, y_test)

# Create Voting Classifier with trained models
voting_clf = VotingClassifier(
    estimators=list(models.items()),
    voting='soft',
    weights=[1.2, 1.1, 1.0]
)

print("\n=== VOTING CLASSIFIER PERFORMANCE ===")
# Initialize float accumulator
y_pred_voting = np.zeros((X_test_top.shape[0], num_classes), dtype=np.float64)

# Weighted probability sum
for i, (name, model) in enumerate(models.items()):
    y_pred_voting += model.predict_proba(X_test_top) * voting_clf.weights[i]

# Final predictions
y_pred_voting = np.argmax(y_pred_voting, axis=1)
print(classification_report(y_test, y_pred_voting, target_names=label_encoder.classes_))
print("F2 Score:", fbeta_score(y_test, y_pred_voting, average='weighted', beta=2))

# === 15. SAVE MODELS ===
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
for name, model in models.items():
    joblib.dump(model, f'{name}_model_{timestamp}.joblib')

# Save voting classifier metadata (not the object itself, due to compatibility issues)
voting_meta = {
    'weights': voting_clf.weights,
    'estimator_names': list(models.keys()),
    'classes_': voting_clf.classes_,
    'voting': voting_clf.voting
}
joblib.dump(voting_meta, f'voting_meta_{timestamp}.pkl')

import joblib
from datetime import datetime

# Generate timestamp
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# Save individual models (if you still have them)
if all(m in globals() for m in ['xgb', 'cat', 'lgb']):
    joblib.dump(xgb, f'xgb_model_{timestamp}.joblib')
    joblib.dump(cat, f'cat_model_{timestamp}.joblib')
    joblib.dump(lgb, f'lgb_model_{timestamp}.joblib')

# Save VotingClassifier (works if already fitted)
try:
    joblib.dump(voting_clf, f'voting_clf_{timestamp}.joblib')
    print("‚úÖ VotingClassifier saved successfully")
except Exception as e:
    print(f"‚ö†Ô∏è Error saving VotingClassifier: {str(e)}")
    print("\nüîß Workaround: Saving components manually...")

    # Manual save fallback
    voting_meta = {
        'classes_': voting_clf.classes_,
        'estimator_names': [name for name, _ in voting_clf.estimators],
        'weights': voting_clf.weights,
        'voting': voting_clf.voting
    }
    joblib.dump(voting_meta, f'voting_meta_{timestamp}.pkl')
    print("‚úÖ Saved VotingClassifier metadata as fallback")

# Save preprocessing artifacts
artifacts = {
    'label_encoder': label_encoder,
    'feature_columns': X.columns.tolist() if 'X' in globals() else None,
    'top_feature_indices': top_feature_indices if 'top_feature_indices' in globals() else None
}
joblib.dump(artifacts, f'preprocessing_{timestamp}.pkl')

